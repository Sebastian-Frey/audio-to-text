{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "import warnings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extraction(file, is_link=False, model_name=\"small\", display_text=False):\n",
    "    \"\"\"\n",
    "    Extracts text from an audio file or YouTube video link using the specified Whisper model.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    file : str\n",
    "        The path to the audio file or the YouTube video link.\n",
    "    is_link : bool, optional\n",
    "        Whether the input is a YouTube video link. The default is False.\n",
    "    model_name : str, optional\n",
    "        The name of the Whisper model to use for transcription. The default is \"small\".\n",
    "    display_text : bool, optional\n",
    "        Whether to display the extracted text. The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The extracted text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the appropriate Whisper model\n",
    "        model = whisper.load_model(model_name)\n",
    "        \n",
    "        if is_link:\n",
    "            yt = YouTube(file)\n",
    "            audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "            if not audio_stream:\n",
    "                raise Exception(\"No audio stream found in the video.\")\n",
    "            \n",
    "            audio_file = audio_stream.download(filename='audio.mp4')\n",
    "            file = audio_file  # Update file variable to the downloaded audio file\n",
    "\n",
    "        # Perform transcription\n",
    "        result = model.transcribe(file)\n",
    "\n",
    "        if display_text:\n",
    "            display(Markdown(result[\"text\"]))\n",
    "\n",
    "        # Clean up the downloaded audio file if it's a link\n",
    "        if is_link:\n",
    "            os.remove(audio_file)\n",
    "\n",
    "        return result[\"text\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Example usage with a YouTube link\n",
    "ted_talk_url = \"https://www.youtube.com/watch?v=z7e7gtU3PHY\"\n",
    "text = text_extraction(ted_talk_url, is_link=True, model_name=\"small\", display_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "# store text in a .txt file\n",
    "with open(\"transcript.txt\", \"w\") as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT_summarize(file_path, model='gpt-3.5-turbo', display_text=False):\n",
    "    \"\"\"\n",
    "    Extracts text from an audio file or a YouTube video link using a specified Whisper model.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    file : str\n",
    "        The path to the audio file or the YouTube video link.\n",
    "    is_link : bool, optional\n",
    "        Indicates if 'file' is a YouTube video link. If True, the video's audio will be downloaded for processing.\n",
    "        The default is False.\n",
    "    model_name : str, optional\n",
    "        Specifies the Whisper model to use for transcription. Valid options include \"tiny\", \"base\", \"small\", \n",
    "        \"medium\", and \"large\". The default is \"small\".\n",
    "    display_text : bool, optional\n",
    "        If True, displays the extracted text using Markdown format. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The extracted text as a string. Returns an empty string and prints an error message in case of failure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    prompt = f\"Summarize the main topic of this text in one or two sentences:\\n\\n{text}\"\n",
    "\n",
    "    # Access ChatOpenAI to summarize the text\n",
    "    llm = ChatOpenAI(temperature=0.1, model = model)\n",
    "    summary = llm.invoke(prompt)\n",
    "\n",
    "    # Display the summarized text if requested\n",
    "    if display_text:\n",
    "        display(Markdown(summary.content))\n",
    "\n",
    "    return summary.content\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# main topic\n",
    "print(\"Summary:\")\n",
    "summary = GPT_summarize(\"transcript.txt\", display_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def GPT_summarize(file_path, summary_style='main_topic', model='gpt-3.5-turbo', display_text=False):\n",
    "    \"\"\"\n",
    "    Summarizes the contents of a text file using a specified OpenAI model.\n",
    "\n",
    "    Arguments:\n",
    "    ---------\n",
    "    file_path : str\n",
    "        Path to the text file to be summarized.\n",
    "    summary_style : str, optional\n",
    "        Type of summary needed: 'main_topic', 'abridged', or 'descriptive'.\n",
    "        Default is 'main_topic'.\n",
    "    model : str, optional\n",
    "        Model to use for the AI summarization, options are 'gpt-3.5-turbo' or 'gpt-4-turbo'.\n",
    "        Default is 'gpt-3.5-turbo'.\n",
    "    display_text : bool, optional\n",
    "        If True, displays the summarized text using Markdown format. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The summarized text. If an invalid summary style is provided, a ValueError is raised.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    The function relies on the `langchain_openai.ChatOpenAI` class to interface with OpenAI's API.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Generate the prompt based on the desired summary style\n",
    "    if summary_style == 'main_topic':\n",
    "        prompt = f\"Summarize the main topic of this text in one or two sentences:\\n\\n{text}\"\n",
    "    elif summary_style == 'abridged':\n",
    "        prompt = f\"Provide an abridged summary of this text in 5-10 bullet points:\\n\\n{text}\"\n",
    "    elif summary_style == 'descriptive':\n",
    "        prompt = f\"Write a detailed summary of this text with a character limit of 3000 to 3500 characters:\\n\\n{text}\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid summary style specified. Choose 'main_topic', 'abridged', or 'descriptive'.\")\n",
    "\n",
    "    # Access ChatOpenAI to summarize the text\n",
    "    llm = ChatOpenAI(temperature=0.1, model = model)\n",
    "    summary = llm.invoke(prompt)\n",
    "\n",
    "    # Display the summarized text if requested\n",
    "    if display_text:\n",
    "        display(Markdown(summary.content))\n",
    "\n",
    "    return summary.content\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# main topic\n",
    "print(\"Main Topic Summary:\")\n",
    "summary = GPT_summarize(\"transcript.txt\", summary_style=\"main_topic\", display_text=True)\n",
    "\n",
    "# bullet points\n",
    "print(\"\\nAbridged Summary:\")\n",
    "summary = GPT_summarize(\"transcript.txt\", summary_style=\"abridged\", display_text=True)\n",
    "\n",
    "# descriptive\n",
    "print(\"\\nDescriptive Summary:\")\n",
    "summary = GPT_summarize(\"transcript.txt\", summary_style=\"descriptive\", display_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioToSummary:\n",
    "\n",
    "    def __init__(self, link, is_link, model_name_whisper='small', model_name_llm='gpt-3.5-turbo'):\n",
    "        \"\"\"\n",
    "        Initialize the AudioToSummary instance with links and model specifications.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        link : str\n",
    "            The URL or path to the audio file to be processed. This could be a local path or a URL to a YouTube video.\n",
    "        is_link : bool\n",
    "            A flag to indicate whether the 'link' parameter is a URL to a YouTube video or a local file path.\n",
    "        model_name_whisper : str, optional\n",
    "            The name of the Whisper model to use for transcription. Defaults to 'small'.\n",
    "        model_name_llm : str, optional\n",
    "            The name of the language model to use for generating summaries. Defaults to 'gpt-3.5-turbo'.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        text : str\n",
    "            The text extracted from the audio file or YouTube video.\n",
    "        _summary : str or None\n",
    "            Cached value of the main topic summary. Calculated lazily.\n",
    "        _description : str or None\n",
    "            Cached value of the descriptive summary. Calculated lazily.\n",
    "        _abridged_summary : str or None\n",
    "            Cached value of the abridged summary. Calculated lazily.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The attributes `_summary`, `_description`, and `_abridged_summary` are lazy-loaded, meaning\n",
    "        they are only computed when first accessed and if `text` is successfully extracted.\n",
    "        \"\"\"\n",
    "        self.model_name_whisper = model_name_whisper\n",
    "        self.link = link\n",
    "        self.model_name_llm = model_name_llm\n",
    "        self.is_link = is_link\n",
    "        self.text = self.text_extraction(self.link, is_link)\n",
    "        self._summary = None\n",
    "        self._description = None\n",
    "        self._abridged_summary = None\n",
    "\n",
    "    @property\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Retrieve or compute the main topic summary of the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The main topic summary of the text. If `text` is not loaded, it returns None.\n",
    "        \"\"\"\n",
    "        if self._summary is None and self.text:  # Generate summary only if text is loaded and summary not already generated\n",
    "            self._summary = self.GPT_summarize(self.text)\n",
    "        return self._summary\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        \"\"\"\n",
    "        Retrieve or compute the descriptive summary of the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The descriptive summary of the text. If `text` is not loaded, it returns None.\n",
    "        \"\"\"\n",
    "        if self._description is None and self.text:  # Generate descriptive summary only if text is loaded and not already generated\n",
    "            self._description = self.GPT_summarize(self.text, summary_style='descriptive')\n",
    "        return self._description\n",
    "\n",
    "    @property\n",
    "    def abridged_summary(self):\n",
    "        \"\"\"\n",
    "        Retrieve or compute the abridged summary of the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The abridged summary of the text. If `text` is not loaded, it returns None.\n",
    "        \"\"\"\n",
    "        if self._abridged_summary is None and self.text:  # Generate abridged summary only if text is loaded and not already generated\n",
    "            self._abridged_summary = self.GPT_summarize(self.text, summary_style='abridged_summary')\n",
    "        return self._abridged_summary\n",
    "\n",
    "\n",
    "    def text_extraction(self, file, is_link=False):\n",
    "        \"\"\"\n",
    "        Extracts text from an audio file or YouTube video link using the specified Whisper model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        file : str\n",
    "            The path to the audio file or the YouTube video link.\n",
    "        is_link : bool\n",
    "            Specifies whether the input is a YouTube video link. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            The extracted text if successful, otherwise returns an empty string if an error occurs.\n",
    "\n",
    "        Notes:\n",
    "        -----\n",
    "        Handles the downloading and deletion of the audio file if the source is a YouTube link.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            model = whisper.load_model(self.model_name_whisper)\n",
    "            if is_link:\n",
    "                yt = YouTube(file)\n",
    "                audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "                if not audio_stream:\n",
    "                    raise Exception(\"No audio stream found in the video.\")\n",
    "\n",
    "                audio_file = audio_stream.download(filename='audio.mp4')\n",
    "                file = audio_file  # Update file variable to the downloaded audio file\n",
    "\n",
    "            result = model.transcribe(file)\n",
    "            text = result[\"text\"]\n",
    "\n",
    "            if is_link:\n",
    "                os.remove(audio_file)\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def GPT_summarize(self, text, summary_style='main_topic', model='gpt-3.5-turbo'):\n",
    "        \"\"\"\n",
    "        Summarizes the text using a specified OpenAI model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        text : str\n",
    "            The text to be summarized.\n",
    "        summary_style : str, optional\n",
    "            The type of summary required: 'main_topic', 'abridged_summary', or 'descriptive'.\n",
    "            Defaults to 'main_topic'.\n",
    "        model : str, optional\n",
    "            The model to use for the AI summarization, with options including 'gpt-3.5-turbo' or 'gpt-4-turbo'.\n",
    "            Defaults to 'gpt-3.5-turbo'.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            The summarized text. Raises a ValueError if an invalid summary style is provided.\n",
    "\n",
    "        Notes:\n",
    "        -----\n",
    "        Leverages the OpenAI's GPT model for generating summaries based on the specified style.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the prompt based on the desired summary style\n",
    "        if summary_style == 'main_topic':\n",
    "            prompt = f\"Summarize the main topic of this text in one or two sentences:\\n\\n{text}\"\n",
    "        elif summary_style == 'abridged_summary':\n",
    "            prompt = f\"Provide an abridged summary of this text in 5-10 bullet points:\\n\\n{text}\"\n",
    "        elif summary_style == 'descriptive':\n",
    "            prompt = f\"Write a detailed summary of this text with a character limit of 3000 to 3500 characters:\\n\\n{text}\"\n",
    "        else:\n",
    "            raise ValueError(\"Invalid summary style specified. Choose 'main_topic', 'abridged', or 'descriptive'.\")\n",
    "\n",
    "        # Access ChatOpenAI to summarize the text\n",
    "        llm = ChatOpenAI(temperature=0.1, model = model)\n",
    "        summary = llm.invoke(prompt)\n",
    "\n",
    "        return summary.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioToSummary:\n",
    "\n",
    "    def __init__(self, link, is_link, model_name_whisper='small', model_name_llm='gpt-3.5-turbo'):\n",
    "        \"\"\"\n",
    "        Initialize the AudioToSummary instance with links and model specifications.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        link : str\n",
    "            The URL or path to the audio file to be processed. This could be a local path or a URL to a YouTube video.\n",
    "        is_link : bool\n",
    "            A flag to indicate whether the 'link' parameter is a URL to a YouTube video or a local file path.\n",
    "        model_name_whisper : str, optional\n",
    "            The name of the Whisper model to use for transcription. Defaults to 'small'.\n",
    "        model_name_llm : str, optional\n",
    "            The name of the language model to use for generating summaries. Defaults to 'gpt-3.5-turbo'.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        text : str\n",
    "            The text extracted from the audio file or YouTube video.\n",
    "        _summary : str or None\n",
    "            Cached value of the main topic summary. Calculated lazily.\n",
    "        _description : str or None\n",
    "            Cached value of the descriptive summary. Calculated lazily.\n",
    "        _abridged_summary : str or None\n",
    "            Cached value of the abridged summary. Calculated lazily.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The attributes `_summary`, `_description`, and `_abridged_summary` are lazy-loaded, meaning\n",
    "        they are only computed when first accessed and if `text` is successfully extracted.\n",
    "        \"\"\"\n",
    "        self.model_name_whisper = model_name_whisper\n",
    "        self.link = link\n",
    "        self.model_name_llm = model_name_llm\n",
    "        self.is_link = is_link\n",
    "        self.text = self.text_extraction(self.link, is_link)\n",
    "        self._summary = None\n",
    "        self._description = None\n",
    "        self._abridged_summary = None\n",
    "\n",
    "    @property\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Retrieve or compute the main topic summary of the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The main topic summary of the text. If `text` is not loaded, it returns None.\n",
    "        \"\"\"\n",
    "        if self._summary is None and self.text:  # Generate summary only if text is loaded and summary not already generated\n",
    "            self._summary = self.GPT_summarize(self.text)\n",
    "        return self._summary\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        \"\"\"\n",
    "        Retrieve or compute the descriptive summary of the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The descriptive summary of the text. If `text` is not loaded, it returns None.\n",
    "        \"\"\"\n",
    "        if self._description is None and self.text:  # Generate descriptive summary only if text is loaded and not already generated\n",
    "            self._description = self.GPT_summarize(self.text, summary_style='descriptive')\n",
    "        return self._description\n",
    "\n",
    "    @property\n",
    "    def abridged_summary(self):\n",
    "        \"\"\"\n",
    "        Retrieve or compute the abridged summary of the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            The abridged summary of the text. If `text` is not loaded, it returns None.\n",
    "        \"\"\"\n",
    "        if self._abridged_summary is None and self.text:  # Generate abridged summary only if text is loaded and not already generated\n",
    "            self._abridged_summary = self.GPT_summarize(self.text, summary_style='abridged_summary')\n",
    "        return self._abridged_summary\n",
    "\n",
    "\n",
    "    def text_extraction(self, file, is_link=False):\n",
    "        \"\"\"\n",
    "        Extracts text from an audio file or YouTube video link using the specified Whisper model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        file : str\n",
    "            The path to the audio file or the YouTube video link.\n",
    "        is_link : bool\n",
    "            Specifies whether the input is a YouTube video link. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            The extracted text if successful, otherwise returns an empty string if an error occurs.\n",
    "\n",
    "        Notes:\n",
    "        -----\n",
    "        Handles the downloading and deletion of the audio file if the source is a YouTube link.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            model = whisper.load_model(self.model_name_whisper)\n",
    "            if is_link:\n",
    "                yt = YouTube(file)\n",
    "                audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "                if not audio_stream:\n",
    "                    raise Exception(\"No audio stream found in the video.\")\n",
    "\n",
    "                audio_file = audio_stream.download(filename='audio.mp4')\n",
    "                file = audio_file  # Update file variable to the downloaded audio file\n",
    "\n",
    "            result = model.transcribe(file)\n",
    "            text = result[\"text\"]\n",
    "\n",
    "            if is_link:\n",
    "                os.remove(audio_file)\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def GPT_summarize(self, text, summary_style='main_topic', model='gpt-3.5-turbo'):\n",
    "        \"\"\"\n",
    "        Summarizes the text using a specified OpenAI model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        text : str\n",
    "            The text to be summarized.\n",
    "        summary_style : str, optional\n",
    "            The type of summary required: 'main_topic', 'abridged_summary', or 'descriptive'.\n",
    "            Defaults to 'main_topic'.\n",
    "        model : str, optional\n",
    "            The model to use for the AI summarization, with options including 'gpt-3.5-turbo' or 'gpt-4-turbo'.\n",
    "            Defaults to 'gpt-3.5-turbo'.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            The summarized text. Raises a ValueError if an invalid summary style is provided.\n",
    "\n",
    "        Notes:\n",
    "        -----\n",
    "        Leverages the OpenAI's GPT model for generating summaries based on the specified style.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate the prompt based on the desired summary style\n",
    "        if summary_style == 'main_topic':\n",
    "            prompt = f\"Summarize the main topic of this text in one or two sentences:\\n\\n{text}\"\n",
    "        elif summary_style == 'abridged_summary':\n",
    "            prompt = f\"Provide an abridged summary of this text in 5-10 bullet points:\\n\\n{text}\"\n",
    "        elif summary_style == 'descriptive':\n",
    "            prompt = f\"Write a detailed summary of this text with a character limit of 3000 to 3500 characters:\\n\\n{text}\"\n",
    "        else:\n",
    "            raise ValueError(\"Invalid summary style specified. Choose 'main_topic', 'abridged', or 'descriptive'.\")\n",
    "\n",
    "        # Access ChatOpenAI to summarize the text\n",
    "        llm = ChatOpenAI(temperature=0.1, model = model)\n",
    "        summary = llm.invoke(prompt)\n",
    "\n",
    "        return summary.content\n",
    "# Example 1\n",
    "processor = AudioToSummary(link =\"https://www.youtube.com/watch?v=z7e7gtU3PHY\",is_link=True)\n",
    "print('summary: ', processor.summary)\n",
    "print()\n",
    "print('description: ', processor.description)\n",
    "print()\n",
    "print('Abridget summary: ', processor.abridged_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "Veritasium = AudioToSummary(link =\"https://www.youtube.com/watch?v=A5w-dEgIU1M\",is_link=True)\n",
    "print('summary: ', Veritasium.summary)\n",
    "print()\n",
    "print('description: ', Veritasium.description)\n",
    "print()\n",
    "print('Abridget summary: ', Veritasium.abridged_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AudiotoSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
